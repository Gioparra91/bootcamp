{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLU9 - Regression: Exercise notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you will practice the following:\n",
    "* Gradient Descent\n",
    "* Simple Linear Regression\n",
    "* Multiple Linear Regression\n",
    "* Using scikit learn linear regression implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression & Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Linear Regression formula\n",
    "\n",
    "$$\\hat{y} = \\beta_0 + \\beta_1 x$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_linear_regression_output(x, b0, b1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x : pandas.Series with shape (num_observations, 1)\n",
    "            The input data to be used in y_hat.\n",
    "        b0 : float\n",
    "            The intercept in y_hat.\n",
    "        b1 : float\n",
    "            The coefficient in y_hat.\n",
    "    \n",
    "    Returns:\n",
    "        y_hat : numpy.array with shape\n",
    "            The prediction made by the simple linear regression.\n",
    "    \"\"\"\n",
    "    y_hat = b0 + b1 * x\n",
    "    \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Linear Regression cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$J = \\frac{1}{N} \\sum_{n=1}^N (y_n - \\hat{y}_n)^2 = \\sum_{n=1}^N (y_n - (\\beta_0 + \\beta_1 x_n))^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_linear_regression_cost_function(y, y_hat):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "        y : pandas.Series\n",
    "            The targets.\n",
    "        y_hat : pandas.Series\n",
    "            The predictions made by a simple linear regression.\n",
    "    \n",
    "    Returns:\n",
    "        cost : pandas.Series\n",
    "    \"\"\"\n",
    "    #1) Perform the difference\n",
    "    e = (y - y_hat)\n",
    "    \n",
    "    #2) Now, square the difference\n",
    "    s = e ** 2\n",
    "    \n",
    "    #3) Finally, take the mean.\n",
    "    m = s.mean()\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial J}{\\partial b_0} = \n",
    "\\sum_{n=1}^N \\frac{\\partial J}{\\partial \\hat{y}_n} \\frac{\\partial \\hat{y}_n}{\\partial b_0} = \n",
    "-\\frac{1}{N} \\sum_{n=1}^N 2(y - \\hat{y}_n) $$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial b_1} = \n",
    "\\sum_{n=1}^N \\frac{\\partial J}{\\partial \\hat{y}_n} \\frac{\\partial \\hat{y}_n}{\\partial b_1} = \n",
    "-\\frac{1}{N} \\sum_{n=1}^N 2(y - \\hat{y}_n) x_n $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dJ_b0 = -(2 * (y - y_hat)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dJ_b1 = -(2 * (y - y_hat) * x).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Linear Regression cost function partial derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial J}{\\partial b_0} = - \\frac{1}{N} \\sum_{n=1}^N 2(y_n - \\hat{y}_n) $$\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial b_1} = - \\frac{1}{N} \\sum_{n=1}^N 2(y_n - \\hat{y}_n)x_n $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_linear_regression_gradient(x, y, b0, b1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x : pandas.Series with shape (num_observations, 1)\n",
    "            The input data to be used in y_hat. \n",
    "        y : pandas.Series with shape (num_observations, 1)\n",
    "            The targets.\n",
    "        b0 : float\n",
    "            The intercept in y_hat.\n",
    "        b1 : float\n",
    "            The coefficient in y_hat.\n",
    "    \n",
    "    Returns:\n",
    "        dJ_db0 : float\n",
    "            Partial derivative of J in order to b0.\n",
    "        dJ_db1 : floats\n",
    "            Partial derivative of J in order to b1.\n",
    "    \"\"\"\n",
    "    # 1) Get the predictions.\n",
    "    y_hat = simple_linear_regression_output(x, b0, b1)\n",
    "    \n",
    "    # 2) Compute the difference between the targets and \n",
    "    #    the predictions.\n",
    "    y_dif = y - y_hat\n",
    "    \n",
    "    # 3) Perform the mean as in the formula.\n",
    "    dJ_db0 = -(2 * y_dif).mean()\n",
    "    \n",
    "    # 4) Same thing as 'dJ_db0' but this time you must \n",
    "    #    account for the input 'x'.\n",
    "    dJ_db1 = -((2 * y_dif) * x).mean()\n",
    "    \n",
    "    return dJ_db0, dJ_db1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusting Simple Linear Regression $\\beta_0$ and $\\beta_1$ parameters with gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. _For epoch in 1...epochs:_\n",
    "    1. $d_y = (y - \\hat{y})$\n",
    "    2. $\\beta_0 = \\beta_0 - \\alpha \\frac{\\partial J}{\\partial \\beta_0} = \\beta_0 + \\alpha \\frac{1}{N} \\sum_{n=1}^N 2 d_y$ \n",
    "    3. _For i in 1..K:_\n",
    "        1. $\\beta_i = \\beta_i - \\alpha \\frac{\\partial J}{\\partial \\beta_i} = \\beta_i + \\alpha \\frac{1}{N} \\sum_{n=1}^N 2 d_y x_{i_n}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_linear_regression_gradient_descent(x, y, b0, b1, learning_rate, epochs): \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x : pandas.Series\n",
    "            TODO\n",
    "        y : pandas.Series\n",
    "            TODO\n",
    "        b0 : float\n",
    "            TODO\n",
    "        b1 : float\n",
    "            TODO\n",
    "        learning_rate : float\n",
    "            TODO\n",
    "        epochs : integer\n",
    "            TODO\n",
    "    \n",
    "    Returns\n",
    "        b0 : float\n",
    "            TODO\n",
    "        b1 : float\n",
    "            TODO\n",
    "    \"\"\"\n",
    "    # 1) For a number of epochs:\n",
    "    for epoch in range(epochs):\n",
    "        # 1.1) Get the gradients\n",
    "        dJ_db0, dJ_db1 = simple_linear_regression_gradient(x, y, b0, b1)\n",
    "        \n",
    "        # 1.2) Change b0\n",
    "        b0 = b0 - learning_rate * dJ_db0\n",
    "        \n",
    "        # 1.3) Change b1\n",
    "        b1 = b1 - learning_rate * dJ_db1\n",
    "        \n",
    "    return b0, b1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusting Simple Linear Regression $\\beta_0$ and $\\beta_1$ parameters with stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. _For epoch in 1...epochs:_\n",
    "    1. _X' = shuffle(X)_\n",
    "    2. _For each $x_n$ in $X'$_:\n",
    "        1. $b_0 = b_0 - \\alpha \\frac{\\partial SE}{\\partial b_0} = b_0 + 2 \\alpha (y - \\hat{y})$\n",
    "        2. $b_1 = b_1 - \\alpha \\frac{\\partial SE}{\\partial b_1} = b_1 + 2 \\alpha (y - \\hat{y})x_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import check_random_state\n",
    "\n",
    "def simple_linear_regression_stochastic_gradient_descent(x, y, b0, b1, learning_rate, epochs, random_state): \n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    # ) Create a random numbers generator using TODO\n",
    "    random_state = check_random_state(random_state)\n",
    "    \n",
    "    # ) TODO\n",
    "    data = pd.concat(\n",
    "        (x.to_frame(), y.to_frame()), \n",
    "        axis=1)\n",
    "    data.columns = ['x', 'y']\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Get a shuffled version of x\n",
    "        data_ = data.sample(n=data.shape[0], random_state=random_state)\n",
    "        x_ = data['x']\n",
    "        y_ = data['y']\n",
    "        for n in range(x.shape[0]): \n",
    "            dJ_db0, dJ_db1 = simple_linear_regression_gradient(x_.iloc[[n]], y_.iloc[[n]], b0, b1)\n",
    "            \n",
    "            b0 = b0 - learning_rate * dJ_db0\n",
    "\n",
    "            b1 = b1 - learning_rate * dJ_db1\n",
    "    \n",
    "    return b0, b1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple Linear Regression formula\n",
    "\n",
    "$$\\hat{y} = \\beta_0 + \\sum_{i=1}^K \\beta_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_linear_regression_output(x, betas):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x : pandas.DataFrame with shape (num_observations, num_features)\n",
    "            TODO\n",
    "        betas : pandas.Series with shape (num_features, 1)\n",
    "            TODO\n",
    "    \n",
    "    Returns:\n",
    "        y_hat : numpy.array with shape\n",
    "            The prediction made by the simple linear regression.\n",
    "    \"\"\"\n",
    "    # 1) TODO\n",
    "    betas = betas.values.reshape((betas.shape[0], 1))\n",
    "    \n",
    "    # 2) TODO: TA ERRADO\n",
    "    dot_product = x.dot(betas)\n",
    "    \n",
    "    # 3) TODO\n",
    "    y_hat = betas[0] + dot_product\n",
    "    \n",
    "    # 3) TODO\n",
    "    y_hat = y_hat[0]\n",
    "    \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple Linear Regression cost function\n",
    "\n",
    "$$J = \\frac{1}{N} \\sum_{n=1}^N (y_n - \\hat{y}_n)^2 = \\sum_{n=1}^N (y_n - (\\beta_0 + \\sum_{i=1}^K \\beta_i))^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_linear_regression_cost_function(x, y, betas):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple Linear Regression partial derivatives\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial b_0} = - \\frac{1}{N} \\sum_{n=1}^N 2(y_n - \\hat{y}_n) $$\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial b_1} = - \\frac{1}{N} \\sum_{n=1}^N 2(y_n - \\hat{y}_n)x_{1_n} $$\n",
    "\n",
    "$$...$$\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial b_K} = - \\frac{1}{N} \\sum_{n=1}^N 2(y_n - \\hat{y}_n)x_{K_n} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_linear_regression_gradient(x, y, betas):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x : pandas.DataFrame with shape (num_observations, num_features)\n",
    "            TODO\n",
    "        y : pandas.Series with shape (num_observations,)\n",
    "            TODO\n",
    "        betas : pandas.Series with shape (num_features,)\n",
    "            TODO\n",
    "    \n",
    "    Returns:\n",
    "        dMSE_dbetas : pandas.Series shape (num_features + 1,)\n",
    "            TODO\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    # 1) Get the predictions.\n",
    "    y_hat = multiple_linear_regression_output(x, betas)\n",
    "    \n",
    "    # 2) Compute the difference between the targets and \n",
    "    #    the predictions.\n",
    "    y_dif = y - y_hat\n",
    "    \n",
    "    dMSE_dbetas = np.zeros((x.shape[1], 1))\n",
    "    print(dMSE_dbetas.shape)\n",
    "    \n",
    "    # 3) TODO\n",
    "    dMSE_dbetas[0] = -(2 * y_dif).mean()\n",
    "    \n",
    "    # 4) TODO\n",
    "    for k, col in enumerate(x.columns): \n",
    "        dMSE_dbetas[k] = -((2 * y_dif) * x[col]).mean()\n",
    "    \n",
    "    return pd.Series(dMSE_dbetas[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = pd.Series(np.random.rand(x.shape[1],))\n",
    "\n",
    "xx = pd.DataFrame(scaler.fit_transform(x), columns=x.columns)\n",
    "multiple_linear_regression_gradient(xx, y, betas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusting Multiple Linear Regression $\\beta_i, 0 \\leq i \\leq K$  parameters with gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusting Multiple Linear Regression $\\beta_i, 0 \\leq i \\leq K$  parameters with stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using scikit learn linear regression implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sklearn_stochastic_gradient_linear_regression_details(x, y, learning_rate, epochs, random_state): \n",
    "    \"\"\"\n",
    "    Args: \n",
    "        x : pandas.DataFrame with shape (num_observations, num_features)\n",
    "        \n",
    "        y : pandas.Series with shape (num_observations)\n",
    "        \n",
    "        learning_rate : float\n",
    "        \n",
    "        epochs : integer\n",
    "        \n",
    "        random_state : None, integer or numpy.random.RandomState\n",
    "        \n",
    "    Return:\n",
    "        coefs : numpy array with shape (num_features,)\n",
    "        \n",
    "        intercept : numpy array with shape (1,)\n",
    "        \n",
    "        score : float\n",
    "    \"\"\"\n",
    "    # 1) Create the class instance.\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # 2) Fit the regressor.\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # 3) Extract the coefficients and intercept.\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # 4) Compute the R² score.\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # 5) Normalize coefficients.\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return coefs, normalized_coefs, intercept, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sklearn_close_form_linear_regression_details(x, y):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "        x : pandas.DataFrame with shape (num_observations, num_features)\n",
    "        \n",
    "        y : pandas.Series with shape (num_observations)\n",
    "        \n",
    "    Return:\n",
    "        coefs : numpy array with shape (num_features,)\n",
    "        \n",
    "        intercept : numpy array with shape (1,)\n",
    "        \n",
    "        score : float\n",
    "    \"\"\"\n",
    "    # 1) Create the class instance.\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # 2) Fit the regressor.\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # 3) Extract the coefficients and intercept.\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # 4) Compute the R² score.\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # 5) Normalize coefficients.\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return coefs, normalized_coefs, intercept, score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
